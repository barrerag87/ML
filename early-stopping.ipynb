{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El *Early Stopping* es una forma de regularización utilizada para evitar el sobreajuste durante el entrenamiento de modelos de aprendizaje profundo. Consiste en monitorear el rendimiento del modelo en un conjunto de datos de validación y detener el entrenamiento cuando dicho rendimiento comienza a degradarse, es decir, cuando el error en el conjunto de validación comienza a aumentar, lo que es una señal de sobreajuste.\n",
    "\n",
    "### Algoritmo\n",
    "\n",
    "El procedimiento de Early Stopping implica:\n",
    "1. Dividir el conjunto de datos disponible en tres partes: entrenamiento, validación y prueba.\n",
    "2. Durante el entrenamiento, evaluar periódicamente el modelo en el conjunto de validación después de cada época (una época es una iteración completa sobre el conjunto de datos de entrenamiento).\n",
    "3. Monitorear el error de validación:\n",
    "   - Si el error de validación disminuye, esto sugiere que el modelo aún está aprendiendo patrones generalizables de los datos.\n",
    "   - Si el error de validación comienza a aumentar, esto sugiere que el modelo está empezando a aprender el ruido y los patrones específicos del conjunto de entrenamiento, lo que no generalizará bien a nuevos datos (sobreajuste).\n",
    "4. Detener el entrenamiento cuando el error de validación aumente durante un número determinado de épocas, lo cual es un indicador de que el modelo ha comenzado a sobreajustarse. Este número se denomina \"paciencia\" y es un hiperparámetro que se puede ajustar.\n",
    "\n",
    "### Implementación en Python con Keras\n",
    "\n",
    "Aquí hay un ejemplo de cómo implementar Early Stopping en Python usando Keras con el conjunto de datos MNIST. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2888 - accuracy: 0.9173 - val_loss: 0.1514 - val_accuracy: 0.9567\n",
      "Epoch 2/100\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1263 - accuracy: 0.9634 - val_loss: 0.1168 - val_accuracy: 0.9663\n",
      "Epoch 3/100\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0858 - accuracy: 0.9745 - val_loss: 0.0965 - val_accuracy: 0.9717\n",
      "Epoch 4/100\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0633 - accuracy: 0.9812 - val_loss: 0.0932 - val_accuracy: 0.9713\n",
      "Epoch 5/100\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0492 - accuracy: 0.9855 - val_loss: 0.0833 - val_accuracy: 0.9750\n",
      "Epoch 6/100\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0388 - accuracy: 0.9880 - val_loss: 0.0862 - val_accuracy: 0.9746\n",
      "Epoch 7/100\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.0863 - val_accuracy: 0.9762\n",
      "Epoch 8/100\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0897 - val_accuracy: 0.9756\n",
      "313/313 [==============================] - 0s 872us/step - loss: 0.0905 - accuracy: 0.9753\n",
      "Test accuracy: 0.9753000140190125\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Cargar el conjunto de datos MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalizar los datos\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Convertir etiquetas a categorías one-hot\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Construir el modelo\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Configurar Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Entrenar el modelo con Early Stopping\n",
    "model.fit(x_train, y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
