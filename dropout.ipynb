{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:From C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rodri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2933 - accuracy: 0.9152 - val_loss: 0.1487 - val_accuracy: 0.9543\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1441 - accuracy: 0.9579 - val_loss: 0.1077 - val_accuracy: 0.9659\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1078 - accuracy: 0.9672 - val_loss: 0.0888 - val_accuracy: 0.9726\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0872 - accuracy: 0.9725 - val_loss: 0.0818 - val_accuracy: 0.9755\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0750 - accuracy: 0.9760 - val_loss: 0.0830 - val_accuracy: 0.9735\n",
      "313/313 [==============================] - 0s 866us/step - loss: 0.0830 - accuracy: 0.9735\n",
      "Test accuracy: 0.9735000133514404\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Cargar el conjunto de datos MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalizar los datos\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Convertir etiquetas a categorías one-hot\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Construir el modelo\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),  # Convertir imágenes 2D en vectores 1D\n",
    "    Dense(128, activation='relu'),  # Primera capa densa con 128 neuronas\n",
    "    Dropout(0.2),  # Dropout con una tasa de 20%\n",
    "    Dense(10, activation='softmax')  # Capa de salida con 10 neuronas para las 10 clases\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST es un conjunto de datos clásico en el campo del aprendizaje automático y la visión por computadora, utilizado frecuentemente para benchmarks y en la educación. Consiste en 70,000 imágenes en escala de grises de dígitos escritos a mano del 0 al 9, con un tamaño de 28x28 píxeles. El conjunto de datos se divide típicamente en 60,000 imágenes para entrenamiento y 10,000 para pruebas. MNIST es ampliamente utilizado por su simplicidad y tamaño manejable, y sirve como un buen punto de partida para experimentar con técnicas de aprendizaje automático y redes neuronales.\n",
    "\n",
    "En el código proporcionado anteriormente, se realiza el siguiente proceso:\n",
    "\n",
    "1. **Carga del conjunto de datos MNIST**: se utilizan funciones de Keras para cargar el conjunto de datos MNIST, que ya está dividido en conjuntos de entrenamiento (60,000 imágenes) y pruebas (10,000 imágenes).\n",
    "\n",
    "2. **Normalización de los datos**: las imágenes se normalizan dividiendo los valores de los píxeles por 255. Esto se hace para convertir los valores de los píxeles de un rango de 0 a 255 a un rango de 0 a 1, lo cual es un paso común en el preprocesamiento de imágenes para modelos de aprendizaje profundo, ayudando a acelerar la convergencia durante el entrenamiento.\n",
    "\n",
    "3. **Conversión de etiquetas a formato one-hot**: las etiquetas, que son números enteros del 0 al 9, se convierten a un formato one-hot. En este formato, cada etiqueta se representa como un vector de 10 elementos, donde el índice correspondiente al dígito está marcado con un 1 y el resto con 0. Esto es necesario para la clasificación multiclase en Keras.\n",
    "\n",
    "4. **Construcción del modelo**: se construye un modelo secuencial de Keras que incluye:\n",
    "   - Una capa `Flatten` para transformar las imágenes 2D (28x28 píxeles) en vectores 1D (784 elementos).\n",
    "   - Una capa `Dense` con 128 neuronas y función de activación ReLU.\n",
    "   - Una capa de `Dropout` con una tasa de 20%, lo que significa que el 20% de las neuronas se \"apagarán\" aleatoriamente durante cada iteración de entrenamiento, ayudando a prevenir el sobreajuste.\n",
    "   - Una capa `Dense` final con 10 neuronas (una por cada clase de dígito) y función de activación softmax, que se utiliza para la clasificación multiclase y proporciona una distribución de probabilidad sobre las 10 clases de dígitos.\n",
    "\n",
    "5. **Compilación del modelo**: el modelo se compila con el optimizador `adam` y la función de pérdida `categorical_crossentropy`, que es adecuada para la clasificación multiclase. La precisión (`accuracy`) se utiliza como métrica para evaluar el rendimiento del modelo.\n",
    "\n",
    "6. **Entrenamiento del modelo**: el modelo se entrena utilizando los datos de entrenamiento con etiquetas one-hot durante 5 épocas, y se valida su rendimiento utilizando el conjunto de datos de prueba.\n",
    "\n",
    "7. **Evaluación del modelo**: finalmente, se evalúa el modelo en el conjunto de datos de prueba para determinar su precisión, es decir, qué tan bien el modelo puede clasificar imágenes de dígitos no vistos durante el entrenamiento.\n",
    "\n",
    "Este proceso demuestra cómo implementar una red neuronal básica con dropout para clasificar dígitos escritos a mano, utilizando Keras y el conjunto de datos MNIST."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
